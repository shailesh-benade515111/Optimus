{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 InputLayer False\n",
      "1 Conv2D False\n",
      "2 Conv2D False\n",
      "3 MaxPooling2D False\n",
      "4 Conv2D False\n",
      "5 Conv2D False\n",
      "6 MaxPooling2D False\n",
      "7 Conv2D False\n",
      "8 Conv2D False\n",
      "9 Conv2D False\n",
      "10 MaxPooling2D False\n",
      "11 Conv2D False\n",
      "12 Conv2D False\n",
      "13 Conv2D False\n",
      "14 MaxPooling2D False\n",
      "15 Conv2D False\n",
      "16 Conv2D False\n",
      "17 Conv2D False\n",
      "18 MaxPooling2D False\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG16\n",
    "\n",
    "# Setting the input size now to 64 x 64 pixel \n",
    "img_rows = 64\n",
    "img_cols = 64\n",
    "\n",
    "# Re-loads the VGG16 model without the top or FC layers\n",
    "vgg16 = VGG16(weights = 'imagenet', \n",
    "                 include_top = False , \n",
    "                 input_shape = (img_rows, img_cols, 3))\n",
    "\n",
    "# Here we freeze the last 4 layers \n",
    "# Layers are set to trainable as True by default\n",
    "for layer in vgg16.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# Let's print our layers \n",
    "for (i,layer) in enumerate(vgg16.layers):\n",
    "    print(str(i) + \" \"+ layer.__class__.__name__, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addTopModel(bottom_model, num_classes, D=256):\n",
    "    \"\"\"creates the top or head of the model that will be \n",
    "    placed ontop of the bottom layers\"\"\"\n",
    "    top_model = bottom_model.output\n",
    "    top_model = Flatten(name = \"flatten\")(top_model)\n",
    "    top_model = Dense(D, activation = \"relu\")(top_model)\n",
    "    top_model = Dropout(0.3)(top_model)\n",
    "    top_model = Dense(num_classes, activation = \"softmax\")(top_model)\n",
    "    return top_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2876 images belonging to 4 classes.\n",
      "Found 719 images belonging to 4 classes.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 64, 64, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 8, 8, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               524544    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 15,240,260\n",
      "Trainable params: 525,572\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG16\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_data_dir = './train'\n",
    "validation_data_dir = './valid'\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=20,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    " \n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    " \n",
    "# Change the batchsize according to your system RAM\n",
    "train_batchsize = 16\n",
    "val_batchsize = 10\n",
    " \n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=train_batchsize,\n",
    "        class_mode='categorical')\n",
    " \n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=val_batchsize,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "\n",
    "# Re-loads the VGG16 model without the top or FC layers\n",
    "vgg16 = VGG16(weights = 'imagenet', \n",
    "                 include_top = False, \n",
    "                 input_shape = (img_rows, img_cols, 3))\n",
    "\n",
    "# Freeze layers\n",
    "for layer in vgg16.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# Number of classes in the Flowers-17 dataset\n",
    "num_classes = 4\n",
    "\n",
    "FC_Head = addTopModel(vgg16, num_classes)\n",
    "\n",
    "model = Model(inputs=vgg16.input, outputs=FC_Head)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "2876/2876 [==============================] - 2037s 708ms/step - loss: 0.4938 - acc: 0.7919 - val_loss: 0.3817 - val_acc: 0.8329\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.38168, saving model to Trained_Models/test2_1.h5\n",
      "Epoch 2/25\n",
      "2876/2876 [==============================] - 2013s 700ms/step - loss: 0.3990 - acc: 0.8328 - val_loss: 0.3435 - val_acc: 0.8482\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.38168 to 0.34350, saving model to Trained_Models/test2_1.h5\n",
      "Epoch 3/25\n",
      "2876/2876 [==============================] - 2029s 705ms/step - loss: 0.3577 - acc: 0.8501 - val_loss: 0.3805 - val_acc: 0.8315\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.34350\n",
      "Epoch 4/25\n",
      "2876/2876 [==============================] - 2017s 701ms/step - loss: 0.3362 - acc: 0.8607 - val_loss: 0.3066 - val_acc: 0.8774\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.34350 to 0.30661, saving model to Trained_Models/test2_1.h5\n",
      "Epoch 5/25\n",
      "2876/2876 [==============================] - 64010s 22s/step - loss: 0.3193 - acc: 0.8672 - val_loss: 0.3934 - val_acc: 0.8454\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.30661\n",
      "Epoch 6/25\n",
      "2876/2876 [==============================] - 2063s 717ms/step - loss: 0.3060 - acc: 0.8753 - val_loss: 0.3255 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.30661\n",
      "Epoch 7/25\n",
      "2876/2876 [==============================] - 2045s 711ms/step - loss: 0.2959 - acc: 0.8792 - val_loss: 0.3488 - val_acc: 0.8565\n",
      "Restoring model weights from the end of the best epoch\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.30661\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "Epoch 00007: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "                   \n",
    "checkpoint = ModelCheckpoint(\"Trained_Models/test2_1.h5\",\n",
    "                             monitor=\"val_loss\",\n",
    "                             mode=\"min\",\n",
    "                             save_best_only = True,\n",
    "                             verbose=1)\n",
    "\n",
    "earlystop = EarlyStopping(monitor = 'val_loss', \n",
    "                          min_delta = 0, \n",
    "                          patience = 3,\n",
    "                          verbose = 1,\n",
    "                          restore_best_weights = True)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss',\n",
    "                              factor = 0.2,\n",
    "                              patience = 3,\n",
    "                              verbose = 1,\n",
    "                              min_delta = 0.00001)\n",
    "\n",
    "# we put our call backs into a callback list\n",
    "callbacks = [earlystop, checkpoint, reduce_lr]\n",
    "\n",
    "# Note we use a very small learning rate \n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = RMSprop(lr = 0.0001),\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = 2876 ,\n",
    "    epochs = epochs,\n",
    "    callbacks = callbacks,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = 719)\n",
    "\n",
    "model.save(\"Trained_Models/test2_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 719 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nb_train_samples = 2876  \n",
    "nb_validation_samples = 719 \n",
    "epochs = 25\n",
    "batch_size = 32\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "classifier = load_model('Trained_Models/test2_1.h5')\n",
    "# We need to recreate our validation generator with shuffle = false\n",
    "\n",
    "valiation_genrator=validation_datagen.flow_from_directory(validation_data_dir,\n",
    "                                                          target_size=(img_rows,img_cols),\n",
    "                                                          batch_size=batch_size,\n",
    "                                                          class_mode='categorical',\n",
    "                                                         shuffle=False)\n",
    "\n",
    "class_labels = valiation_genrator.class_indices\n",
    "class_labels = {v: k for k, v in class_labels.items()}\n",
    "classes = list(class_labels.values())\n",
    "\n",
    "\n",
    "#Confution Matrix and Classification Report\n",
    "Y_pred = classifier.predict_generator(valiation_genrator,  nb_validation_samples // batch_size+1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 2, 0, 1, 0, 0, 3, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 3, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 1, 1, 0, 0, 0, 3, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 3, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 2, 0, 0, 0, 1, 1, 1, 2, 1, 1, 1,\n",
       "       1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 3, 3, 3,\n",
       "       3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], dtype=int64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "                                            precision    recall  f1-score   support\n",
      "\n",
      "                         Grape___Black_rot       0.87      0.77      0.82       235\n",
      "              Grape___Esca_(Black_Measles)       0.80      0.85      0.83       200\n",
      "Grape___Leaf_blight_(Isariopsis_Leaf_Spot)       0.96      0.98      0.97       200\n",
      "                           Grape___healthy       0.91      0.98      0.94        84\n",
      "\n",
      "                                 micro avg       0.88      0.88      0.88       719\n",
      "                                 macro avg       0.88      0.90      0.89       719\n",
      "                              weighted avg       0.88      0.88      0.88       719\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8776077885952712"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
    "print('Classification Report')\n",
    "target_names = list(class_labels.values())\n",
    "print(classification_report(valiation_genrator.classes, y_pred, target_names=target_names))\n",
    "accuracy_score(valiation_genrator.classes,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for single test image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Grape___healthy'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from keras.preprocessing import image # Need to reload as opencv2 seems to have a conflict\n",
    "# create a list containing the class labels\n",
    "img = image.load_img('./teste data/a/h.jpg', target_size=(64, 64))\n",
    "\n",
    "x = image.img_to_array(img)\n",
    "x = x * 1./255\n",
    "x = np.expand_dims(x, axis=0)\n",
    "images = np.vstack([x]) \n",
    "    \n",
    "    # Get Prediction\n",
    "res = np.argmax(classifier.predict(images))\n",
    "disease_list=['Grape___Black_rot', 'Grape___Esca_(Black_Measles)', 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)', 'Grape___healthy']    \n",
    "    # Show image with predicted class\n",
    "#draw_test(\"Prediction\", res, input_original)     \n",
    "# preds_vgg_model = classifier.predict(x)\n",
    "disease = disease_list[int(res)]\n",
    "disease\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "# print(preds_vgg_model)\n",
    "# a=list(preds_vgg_model[0])\n",
    "\n",
    "# maxpos = a.index(max(a)) \n",
    "# print(maxpos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grape___Leaf_blight_(Isariopsis_Leaf_Spot)\n",
      "Grape___Black_rot\n",
      "Grape___healthy\n",
      "Grape___healthy\n",
      "Grape___Black_rot\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "DD=list(train_generator.class_indices.keys())\n",
    "def draw_test(name, pred, im):\n",
    "\n",
    "    rsc = DD[int(pred)]\n",
    "    print(rsc)\n",
    "    BLACK = [0,0,0]\n",
    "    expanded_image = cv2.copyMakeBorder(im, 150, 0, 0, 200 ,cv2.BORDER_CONSTANT,value=BLACK)\n",
    "    cv2.putText(expanded_image, rsc, (10, 20) , cv2.FONT_HERSHEY_SIMPLEX,1, (0,0,255), 2)\n",
    "    cv2.imshow(name, expanded_image)\n",
    "\n",
    "def getRandomImage(path,i):\n",
    "    \"\"\"function loads a random images from a random folder in our test path \"\"\"\n",
    "    folders = list(filter(lambda x: os.path.isdir(os.path.join(path, x)), os.listdir(path)))\n",
    " \n",
    "    path_class = folders[i]\n",
    "    i=i+1\n",
    "    \n",
    "    file_path = path + path_class\n",
    "    file_names = [f for f in listdir(file_path) if isfile(join(file_path, f))]\n",
    "    random_file_index = np.random.randint(0,len(file_names))\n",
    "    image_name = file_names[random_file_index]\n",
    "    return cv2.imread(file_path+\"/\"+image_name)    \n",
    "cnt=0\n",
    "for i in range(5):\n",
    "    input_im = getRandomImage(\"./teste data/\",cnt)\n",
    "    #input_im = image.load_img('./teste data/black_rot/3.jpg', target_size=(64, 64))\n",
    "    input_original = input_im.copy()\n",
    "    input_original = cv2.resize(input_original, None, fx=0.5, fy=0.5, interpolation = cv2.INTER_LINEAR)\n",
    "    \n",
    "    input_im = cv2.resize(input_im, (64, 64), interpolation = cv2.INTER_LINEAR)\n",
    "    input_im = input_im / 255.\n",
    "    input_im = input_im.reshape(1,64,64,3) \n",
    "    \n",
    "    # Get Prediction\n",
    "    res = np.argmax(classifier.predict(input_im))\n",
    "    \n",
    "    # Show image with predicted class\n",
    "    draw_test(\"Prediction\", res, input_original) \n",
    "    cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
